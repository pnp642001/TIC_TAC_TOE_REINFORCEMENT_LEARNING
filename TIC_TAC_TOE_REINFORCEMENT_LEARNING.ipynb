{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TIC_TAC_TOE_REINFORCEMENT_LEARNING.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOY4nKU/6evPFoYQ6XyV7+E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pnp642001/TIC_TAC_TOE_REINFORCEMENT_LEARNING/blob/main/TIC_TAC_TOE_REINFORCEMENT_LEARNING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dpcGklwImWJ",
        "outputId": "51286e6e-5b5b-4506-f438-08b29e18b606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.7.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "#installing the necessary components\n",
        "#Gym is a collection of environments/problems designed for testing and developing reinforcement learning algorithms\n",
        "!pip install gym"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download the environment file\n",
        "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/playing-tictactoe-with-reinforcement-learning-and-openai-gym/gym-tictactoe.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1krDqjIuI6Yg",
        "outputId": "c2642215-ffe4-4d0e-8dea-13eda5df65dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-01 11:21:54--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/playing-tictactoe-with-reinforcement-learning-and-openai-gym/gym-tictactoe.zip\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10119 (9.9K) [application/zip]\n",
            "Saving to: ‘gym-tictactoe.zip’\n",
            "\n",
            "gym-tictactoe.zip   100%[===================>]   9.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-01 11:21:55 (320 MB/s) - ‘gym-tictactoe.zip’ saved [10119/10119]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o gym-tictactoe.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNEGiSoSJA7E",
        "outputId": "1357e039-5d19-4c7d-e43a-031b04e67d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  gym-tictactoe.zip\n",
            "   creating: gym-tictactoe/\n",
            "   creating: gym-tictactoe/gym_tictactoe.egg-info/\n",
            "   creating: gym-tictactoe/gym_tictactoe/\n",
            "  inflating: gym-tictactoe/setup.py  \n",
            "   creating: gym-tictactoe/.ipynb_checkpoints/\n",
            "  inflating: gym-tictactoe/gym_tictactoe.egg-info/PKG-INFO  \n",
            "  inflating: gym-tictactoe/gym_tictactoe.egg-info/SOURCES.txt  \n",
            "  inflating: gym-tictactoe/gym_tictactoe.egg-info/requires.txt  \n",
            "  inflating: gym-tictactoe/gym_tictactoe.egg-info/top_level.txt  \n",
            "  inflating: gym-tictactoe/gym_tictactoe.egg-info/dependency_links.txt  \n",
            "  inflating: gym-tictactoe/gym_tictactoe/__init__.py  \n",
            "   creating: gym-tictactoe/gym_tictactoe/__pycache__/\n",
            "   creating: gym-tictactoe/gym_tictactoe/.ipynb_checkpoints/\n",
            "   creating: gym-tictactoe/gym_tictactoe/envs/\n",
            "  inflating: gym-tictactoe/.ipynb_checkpoints/setup-checkpoint.py  \n",
            "  inflating: gym-tictactoe/gym_tictactoe/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: gym-tictactoe/gym_tictactoe/.ipynb_checkpoints/__init__-checkpoint.py  \n",
            "  inflating: gym-tictactoe/gym_tictactoe/envs/__init__.py  \n",
            "   creating: gym-tictactoe/gym_tictactoe/envs/__pycache__/\n",
            "   creating: gym-tictactoe/gym_tictactoe/envs/.ipynb_checkpoints/\n",
            "  inflating: gym-tictactoe/gym_tictactoe/envs/tictactoe_env.py  \n",
            "  inflating: gym-tictactoe/gym_tictactoe/envs/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: gym-tictactoe/gym_tictactoe/envs/__pycache__/tictactoe_env.cpython-39.pyc  \n",
            "  inflating: gym-tictactoe/gym_tictactoe/envs/.ipynb_checkpoints/__init__-checkpoint.py  \n",
            "  inflating: gym-tictactoe/gym_tictactoe/envs/.ipynb_checkpoints/tictactoe_env-checkpoint.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -e gym-tictactoe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6XBzSYqOAuL",
        "outputId": "ebb490d0-2fe3-4118-de6d-04752fc9ded2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/gym-tictactoe\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from gym-tictactoe==0.0.1) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym->gym-tictactoe==0.0.1) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->gym-tictactoe==0.0.1) (1.7.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->gym-tictactoe==0.0.1) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->gym-tictactoe==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->gym-tictactoe==0.0.1) (0.16.0)\n",
            "Installing collected packages: gym-tictactoe\n",
            "  Running setup.py develop for gym-tictactoe\n",
            "Successfully installed gym-tictactoe-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gym is a library that will allow us to initialize and work with the TicTacToe environment\n",
        "import gym\n",
        "# Random allows us to make random choices when interacting with the environment\n",
        "import random\n",
        "# Custom tictactoe environment\n",
        "import gym_tictactoe\n",
        "\n",
        "#The above pattern followed with the reference of a comment made in Stack-overflow"
      ],
      "metadata": {
        "id": "Nmto3LB-OLae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating an environment\n",
        "\n",
        "env = gym.make(\"TicTacToe-v0\")"
      ],
      "metadata": {
        "id": "WYGjtoYPOe-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiB5LWPDOnC2",
        "outputId": "3d920c65-3cd5-4335-819a-72a717a7bb3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['-', '-', '-'], ['-', '-', '-'], ['-', '-', '-']]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.hash()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Mt0DrU0OOs8x",
        "outputId": "c8045e77-3bac-4ed5-817d-7d83b3dc568e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'---------'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_state, reward, done, info = env.step(0, \"X\")"
      ],
      "metadata": {
        "id": "bfdmZ-qbOvqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8YaQNQ8SOyHl",
        "outputId": "655ae1f4-80cf-44a7-cc87-f9126886b970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'X--------'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyvCdX1WOz36",
        "outputId": "62924cd8-82e0-4eaa-f533-2386e2f4b13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "done"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPsMcDKDO20w",
        "outputId": "1fd0a5b3-ecaa-4688-a62c-ba06a303f4b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znhcaQW7O3a5",
        "outputId": "4c007285-0b3b-44ef-8451-8bf7841d3f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB6uFbR6O5In",
        "outputId": "3c464a6b-3299-4d0d-8d81-5ab595f11c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board\n",
            "['X', '-', '-']\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.available_actions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuFPCVR9O7rn",
        "outputId": "335cde9a-95c3-45b7-fee6-8b74d596ce1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.available_states(\"O\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp120BT7O9my",
        "outputId": "815e171b-5565-47d7-c184-d466f11a9522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('XO-------', (0, 0)),\n",
              " ('X-O------', (0, 0)),\n",
              " ('X--O-----', (0, 0)),\n",
              " ('X---O----', (0, 0)),\n",
              " ('X----O---', (0, 0)),\n",
              " ('X-----O--', (0, 0)),\n",
              " ('X------O-', (0, 0)),\n",
              " ('X-------O', (0, 0))]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.check_done(env.hash())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0Da0i7ZO_t_",
        "outputId": "b217aacf-9dc0-4fd0-a9e0-ff1c5e359514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, (0, 0))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()"
      ],
      "metadata": {
        "id": "nVybhWxSPB6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWZCD3r1PD0s",
        "outputId": "237bdcd6-ad62-46f2-8e21-6f8304c5f1b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# variable to keep track of if the game is over\n",
        "done = False\n",
        "# Good practice to reset environment before you play a game to clear any old game\n",
        "env.reset()\n",
        "# Print the initial board\n",
        "env.render()\n",
        "# Want to keep playing untill game is over\n",
        "while not done:\n",
        "    # Make a random action from the list of available actions for X\n",
        "    new_state, reward, done, info = env.step(random.choice(env.available_actions()), \"X\")\n",
        "    # Print board after X action\n",
        "    env.render()\n",
        "    \n",
        "    # If the game is done on X action we dont want O to make an action\n",
        "    if not done:\n",
        "        # Make a random action from the list of available actions for O\n",
        "        new_state, reward, done, info = env.step(random.choice(env.available_actions()), \"O\")\n",
        "        # Print board after O action\n",
        "        env.render()\n",
        "        \n",
        "# Print the reward after the game is done, reward for X is the first value and O is the second value\n",
        "print(reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hhz349jPGeC",
        "outputId": "f1fe13b4-2cb4-4082-ab75-c8d6a999bcef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n",
            "Board\n",
            "['-', '-', '-']\n",
            "['-', '-', 'X']\n",
            "['-', '-', '-']\n",
            "Board\n",
            "['-', '-', '-']\n",
            "['-', '-', 'X']\n",
            "['O', '-', '-']\n",
            "Board\n",
            "['-', '-', '-']\n",
            "['-', '-', 'X']\n",
            "['O', '-', 'X']\n",
            "Board\n",
            "['O', '-', '-']\n",
            "['-', '-', 'X']\n",
            "['O', '-', 'X']\n",
            "Board\n",
            "['O', '-', '-']\n",
            "['X', '-', 'X']\n",
            "['O', '-', 'X']\n",
            "Board\n",
            "['O', '-', 'O']\n",
            "['X', '-', 'X']\n",
            "['O', '-', 'X']\n",
            "Board\n",
            "['O', '-', 'O']\n",
            "['X', 'X', 'X']\n",
            "['O', '-', 'X']\n",
            "(10, -10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# variable to keep track of if the game is over\n",
        "done = False\n",
        "# Good practice to reset environment before you play a game to clear any old game\n",
        "env.reset()\n",
        "# Want to keep playing untill game is over\n",
        "while not done:\n",
        "    # Make a random action from the list of available actions for X\n",
        "    new_state, reward, done, info = env.step(random.choice(env.available_actions()), \"X\")\n",
        "    # Print state\n",
        "    print(env.hash())\n",
        "    \n",
        "    # If the game is done on X action we dont want O to make an action\n",
        "    if not done:\n",
        "        # Make a random action from the list of available actions for O\n",
        "        new_state, reward, done, info = env.step(random.choice(env.available_actions()), \"O\")\n",
        "        # Print state\n",
        "        print(env.hash())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN9Hl89QPKDe",
        "outputId": "d0509ca7-8f74-4d51-c5c0-de3e0f372f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------X\n",
            "---O----X\n",
            "---O--X-X\n",
            "---O-OX-X\n",
            "---O-OXXX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnezFIH2PO09",
        "outputId": "c2655897-f3ac-4943-9045-927a60eb2a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfiHrVh2PRqU",
        "outputId": "d03e3659-0986-474b-d4d4-a136c46862ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, -10)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.available_actions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNdVDk-JPTjv",
        "outputId": "0a1237b4-f6cc-40c6-cc56-b8130ae8c8ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "    \n",
        "    def __init__(self, env, player=\"X\", alpha=.4, gamma=.9):\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.env = env\n",
        "        self.player = player\n",
        "        self.player_number = 0 if player == \"X\" else 1\n",
        "        self.V = {}"
      ],
      "metadata": {
        "id": "hDYIz0tGPV-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent(Agent):\n",
        "\n",
        "    def select_action(self, epsilon=.1):\n",
        "        # generates random number between 0 and 1 if it is below epsilon we take random action otherwise a greedy action\n",
        "        if (random.random() < epsilon):\n",
        "            # gets a random action from list of available actions\n",
        "            action = random.choice(self.env.available_actions())\n",
        "        else:\n",
        "            # list to store action calculations\n",
        "            q_values = []\n",
        "            # loops through the list of available states and rewards \n",
        "            for state in self.env.available_states(self.player):\n",
        "                # calculates gamma*V(S') + Reward for the state\n",
        "                # example: state = ((\"X--O-----\"), (0,0))\n",
        "                q_values.append(self.gamma*self.V[state[0]] + state[1][self.player_number])\n",
        "            # find the max value of the action calculations\n",
        "            max_value = max(q_values)\n",
        "            # selects indexs of values in q_values that are the max_value\n",
        "            max_indexs = [i for i, j in enumerate(q_values) if j == max_value]\n",
        "            # select a random action from the actions that all have the max_value\n",
        "            action = self.env.available_actions()[random.choice(max_indexs)]\n",
        "        return action"
      ],
      "metadata": {
        "id": "B0JxYdnFPf8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent(Agent):\n",
        "    \n",
        "    def add_states(self):\n",
        "        # adds current state to state value function\n",
        "        if (self.env.hash() not in self.V):\n",
        "            self.V[self.env.hash()] = 0\n",
        "        # adds all states X can get to\n",
        "        for state in self.env.available_states(\"X\"):\n",
        "            if (state[0] not in self.V):\n",
        "                self.V[state[0]] = 0\n",
        "        # adds all states O can get to\n",
        "        for state in self.env.available_states(\"O\"):\n",
        "            if (state[0] not in self.V):\n",
        "                self.V[state[0]] = 0"
      ],
      "metadata": {
        "id": "x8Mx4FxlP7WT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent(Agent):\n",
        "    \n",
        "    def update_state_values(self, new_state, old_state, reward):\n",
        "        # V(S) = V(S) + alpha*(R + gamma*(V(S') - V(S)))\n",
        "        self.V[old_state] = self.V[old_state] + self.alpha*(reward + self.gamma*self.V[new_state] - self.V[old_state])"
      ],
      "metadata": {
        "id": "JAITF19YP_Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def train(episodes):\n",
        "    # create our agents\n",
        "    agent_x = Agent(env, \"X\")\n",
        "    agent_o = Agent(env, \"O\")\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        # while loop for a single game\n",
        "        while not done:\n",
        "            \n",
        "            # X agents turn\n",
        "\n",
        "            # adds states for both agents\n",
        "            agent_x.add_states()\n",
        "            agent_o.add_states()\n",
        "            \n",
        "            # records the state we are in before action\n",
        "            old_state = env.hash()\n",
        "            # get an action using policy\n",
        "            action = agent_x.select_action()\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(action, agent_x.player)\n",
        "            \n",
        "            # update state values for both agents\n",
        "            agent_x.update_state_values(new_state, old_state, reward[agent_x.player_number])\n",
        "            agent_o.update_state_values(new_state, old_state, reward[agent_o.player_number])\n",
        "            \n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if not done:\n",
        "                \n",
        "                # O agents turn\n",
        "                \n",
        "                # adds states for both agents\n",
        "                agent_x.add_states()\n",
        "                agent_o.add_states()\n",
        "\n",
        "                # records the state we are in before action\n",
        "                old_state = env.hash()\n",
        "                # get an action using policy\n",
        "                action = agent_o.select_action()\n",
        "                # performs an action\n",
        "                new_state, reward, done, _ = env.step(action, agent_o.player)\n",
        "\n",
        "                # update state values for both agents\n",
        "                agent_x.update_state_values(new_state, old_state, reward[agent_x.player_number])\n",
        "                agent_o.update_state_values(new_state, old_state, reward[agent_o.player_number])\n",
        "                \n",
        "    return agent_x, agent_o"
      ],
      "metadata": {
        "id": "pg79biugQBGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "agent_x, agent_o = train(110000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHlq8iIkQDGq",
        "outputId": "c827a0a9-c95f-4384-ac7f-1fe3ebdbbe50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 31s, sys: 1.35 s, total: 2min 32s\n",
            "Wall time: 2min 32s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def test_x(episodes):\n",
        "    # counters to keep track of results\n",
        "    win = 0\n",
        "    tie = 0\n",
        "    loss = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "            \n",
        "            # adds states for X only because we are acting randomly and not updating state values for O\n",
        "            agent_x.add_states()\n",
        "            \n",
        "            # always get the best action\n",
        "            x_action = agent_x.select_action(epsilon=0)\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, agent_x.player)\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "                \n",
        "                # O agents turn\n",
        "                \n",
        "                # adds states for X only because we are acting randomly and not updating state values for O\n",
        "                agent_x.add_states()\n",
        "                \n",
        "                # O always makes a random action from the available actions\n",
        "                o_action = random.choice(env.available_actions())\n",
        "                new_state, reward, done, _ = env.step(o_action, \"O\")\n",
        "                \n",
        "        # record results when game is done\n",
        "        if (reward == (10, -10)):\n",
        "            win+=1\n",
        "        elif (reward == (-10, 10)):\n",
        "            loss+=1\n",
        "        elif (reward == (0, 0)):\n",
        "            tie+=1\n",
        "    return win, loss, tie"
      ],
      "metadata": {
        "id": "2R1JRPcMQFJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 10000\n",
        "\n",
        "win, loss, tie = test_x(episodes)\n",
        "\n",
        "print(\"Win:\", win, \"Tie:\", tie, \"Loss:\", loss)\n",
        "print(\"Win Rate:\", win/episodes*100, \"Tie Rate:\", tie/episodes*100, \"Loss Rate:\", loss/episodes*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTm4CiDGQvAl",
        "outputId": "47c477bb-dfda-4f8a-eb93-c826b4f34a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Win: 9889 Tie: 111 Loss: 0\n",
            "Win Rate: 98.89 Tie Rate: 1.11 Loss Rate: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def test_o(episodes):\n",
        "    # counters to keep track of results\n",
        "    win = 0\n",
        "    tie = 0\n",
        "    loss = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "            \n",
        "            # adds states for O only because we are acting randomly and not updating state values for X\n",
        "            agent_o.add_states()\n",
        "            \n",
        "            # X always makes a random action from the available actions\n",
        "            x_action = random.choice(env.available_actions())\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, \"X\")\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "                \n",
        "                # O agents turn\n",
        "                \n",
        "                # adds states for O only because we are acting randomly and not updating state values for X\n",
        "                agent_o.add_states()\n",
        "                \n",
        "                # always get the best action\n",
        "                o_action = agent_o.select_action(epsilon=0)\n",
        "                new_state, reward, done, _ = env.step(o_action, agent_o.player)\n",
        "                \n",
        "        # record results when game is done\n",
        "        if (reward == (-10, 10)):\n",
        "            win+=1\n",
        "        elif (reward == (10, -10)):\n",
        "            loss+=1\n",
        "        elif (reward == (0, 0)):\n",
        "            tie+=1\n",
        "    return win, loss, tie"
      ],
      "metadata": {
        "id": "BzO2OaXQQxSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 10000\n",
        "\n",
        "win, loss, tie = test_o(episodes)\n",
        "\n",
        "print(\"Win:\", win, \"Tie:\", tie, \"Loss:\", loss)\n",
        "print(\"Win Rate:\", win/episodes*100, \"Tie Rate:\", tie/episodes*100, \"Loss Rate:\", loss/episodes*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcC0HaWRQ5Wn",
        "outputId": "f188e3ed-a9cc-4897-e1b1-0a2b98938ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Win: 8790 Tie: 1210 Loss: 0\n",
            "Win Rate: 87.9 Tie Rate: 12.1 Loss Rate: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def test(episodes):\n",
        "    # counters to keep track of results\n",
        "    x_win = 0\n",
        "    o_win = 0\n",
        "    tie = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "            \n",
        "            # adds states for both agents because we are using select_action on both\n",
        "            agent_x.add_states()\n",
        "            agent_o.add_states()\n",
        "            \n",
        "            # always get the best action\n",
        "            x_action = agent_x.select_action(epsilon=0)\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, \"X\")\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "                \n",
        "                # O agents turn\n",
        "                \n",
        "                # adds states for both agents because we are using select_action on both\n",
        "                agent_x.add_states()\n",
        "                agent_o.add_states()\n",
        "                \n",
        "                # always get the best action\n",
        "                o_action = agent_o.select_action(epsilon=0)\n",
        "                new_state, reward, done, _ = env.step(o_action, \"O\")\n",
        "                \n",
        "        # record results when game is done\n",
        "        if (reward == (-10, 10)):\n",
        "            o_win+=1\n",
        "        elif (reward == (10, -10)):\n",
        "            x_win+=1\n",
        "        elif (reward == (0, 0)):\n",
        "            tie+=1\n",
        "    return x_win, o_win, tie"
      ],
      "metadata": {
        "id": "dXSaM1HSQ658"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 10000\n",
        "\n",
        "x_win, o_win, tie = test(episodes)\n",
        "\n",
        "print(\"X Win:\", x_win, \"Tie:\", tie, \"O Win:\", o_win)\n",
        "print(\"X Win Rate:\", x_win/episodes*100, \"Tie Rate:\", tie/episodes*100, \"O Win Rate:\", o_win/episodes*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G78fNN2RCGl",
        "outputId": "e8e8bd18-551d-4956-e2c2-4bf5ebc3f702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Win: 0 Tie: 10000 O Win: 0\n",
            "X Win Rate: 0.0 Tie Rate: 100.0 O Win Rate: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def play_as_x(episodes=1):\n",
        "    # counters to keep track of results\n",
        "    x_win = 0\n",
        "    o_win = 0\n",
        "    tie = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "            \n",
        "            # print the environment before you go\n",
        "            env.render()\n",
        "            # print available actions\n",
        "            print(env.available_actions())\n",
        "            \n",
        "            # adds states for O only because we are controlling X\n",
        "            agent_o.add_states()\n",
        "            \n",
        "            # get user input\n",
        "            x_action = int(input())\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, \"X\")\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "                \n",
        "                # O agents turn\n",
        "                \n",
        "                # adds states for O only because we are controlling X \n",
        "                agent_o.add_states()\n",
        "                \n",
        "                # always get the best action\n",
        "                o_action = agent_o.select_action(epsilon=0)\n",
        "                new_state, reward, done, _ = env.step(o_action, \"O\")\n",
        "        \n",
        "        env.render()\n",
        "        # record results when game is done\n",
        "        if (reward == (-10, 10)):\n",
        "            print(\"You Lose\")\n",
        "        elif (reward == (10, -10)):\n",
        "            print(\"You Win\")\n",
        "        elif (reward == (0, 0)):\n",
        "            print(\"Tie\")"
      ],
      "metadata": {
        "id": "nbOj-o8iREYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play_as_x()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3qeN2vzRIDq",
        "outputId": "86c89f44-8177-4074-9c24-929ab08a1391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "2\n",
            "Board\n",
            "['-', '-', 'X']\n",
            "['-', 'O', '-']\n",
            "['-', '-', '-']\n",
            "[0, 1, 3, 5, 6, 7, 8]\n",
            "8\n",
            "Board\n",
            "['-', '-', 'X']\n",
            "['-', 'O', 'O']\n",
            "['-', '-', 'X']\n",
            "[0, 1, 3, 6, 7]\n",
            "3\n",
            "Board\n",
            "['-', '-', 'X']\n",
            "['X', 'O', 'O']\n",
            "['O', '-', 'X']\n",
            "[0, 1, 7]\n",
            "1\n",
            "Board\n",
            "['O', 'X', 'X']\n",
            "['X', 'O', 'O']\n",
            "['O', '-', 'X']\n",
            "[7]\n",
            "7\n",
            "Board\n",
            "['O', 'X', 'X']\n",
            "['X', 'O', 'O']\n",
            "['O', 'X', 'X']\n",
            "Tie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def play_as_o(episodes=1):\n",
        "    # counters to keep track of results\n",
        "    x_win = 0\n",
        "    o_win = 0\n",
        "    tie = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "            \n",
        "            # adds states for X only because we are controlling O\n",
        "            agent_x.add_states()\n",
        "            \n",
        "            # always get the best action\n",
        "            x_action = agent_x.select_action(epsilon=0)\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, \"X\")\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "                \n",
        "                # O agents turn\n",
        "                \n",
        "                # print the environment before you go\n",
        "                env.render()\n",
        "                # print available actions\n",
        "                print(env.available_actions())\n",
        "                \n",
        "                # adds states for X only because we are controlling O\n",
        "                agent_x.add_states()\n",
        "                \n",
        "                # get user input\n",
        "                o_action = int(input())\n",
        "                new_state, reward, done, _ = env.step(o_action, \"O\")\n",
        "        \n",
        "        env.render()\n",
        "        # record results when game is done\n",
        "        if (reward == (-10, 10)):\n",
        "            print(\"You Win\")\n",
        "        elif (reward == (10, -10)):\n",
        "            print(\"You Lose\")\n",
        "        elif (reward == (0, 0)):\n",
        "            print(\"Tie\")"
      ],
      "metadata": {
        "id": "s-K73LXKRMUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play_as_o()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRft3HoeRWOp",
        "outputId": "c9df7630-abda-4e18-c69c-6dbe8ebd3994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board\n",
            "['-', '-', '-']\n",
            "['-', 'X', '-']\n",
            "['-', '-', '-']\n",
            "[0, 1, 2, 3, 5, 6, 7, 8]\n",
            "0\n",
            "Board\n",
            "['O', 'X', '-']\n",
            "['-', 'X', '-']\n",
            "['-', '-', '-']\n",
            "[2, 3, 5, 6, 7, 8]\n",
            "7\n",
            "Board\n",
            "['O', 'X', '-']\n",
            "['-', 'X', '-']\n",
            "['X', 'O', '-']\n",
            "[2, 3, 5, 8]\n",
            "2\n",
            "Board\n",
            "['O', 'X', 'O']\n",
            "['X', 'X', '-']\n",
            "['X', 'O', '-']\n",
            "[5, 8]\n",
            "5\n",
            "Board\n",
            "['O', 'X', 'O']\n",
            "['X', 'X', 'O']\n",
            "['X', 'O', 'X']\n",
            "Tie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JzVnF-mpRYaP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}